Predprocesiranje:
tokenizacija -> dijeljenje rečenica na riječi:
  1. izbacivanje specijalnih znakova (zamjena sa prazninama)
  2. odbacivanje riječi koje su duže od 25 znakova
  3. stemming
    Korišten je Snowball (Porter2) stemmer zato što je manje agresivan od Lancaster stemmer-a, a brži od Porter stemmera. Uvođenjem stemmer-a naraslo je vrijeme izvođenja pretprocesiranja i to za ~4 puta (koristi se stemming python modul). Trebalo bi koristiti neku brzu c/c++ implementaciju stemming postupka.

Nije se koristio lematizator zato što mislim da je bitno očuvati riječi što je moguče više onakve kakve jesu. Primjerice, ne bi bilo dobro zamijeniti is sa be, jer je korisnik možda baš htio dokumente gdje se pojavljuje is. Lematizator bi is token zamijenio s be tokenom i tu bi se izbugila informacija. Kada bi postojala potreba za lematizatorom tada bi se uz python koristio spacy lematizator i to zato što je brži od nltk stemmer-a. 
-------------------------- 
Algoritmi:

1. Bag of words. Normalizirana verzija. Broje se pojavljivanja svakog tokena unutar nekog dokumenta. Za svaki token gleda se koliko puta se on pojavio unutar dokumenta i onda se ta vrijednost normalizira s velicinom dokumenta. Na taj način se postiže da kraći dokumenti u kojima broj pojavljivanje čini veći postotak unutar dokumenta imaju snažniji utjecaj nego dokumenti u kojima se više puta pojavljuje dotični token.

DOBRO: brzina, jednostavnost, normalizacija
LOSE: ne uzima nikakvu globalnu informaciju

2. Vector space algorithm

Veličina problema:
- broj dokumeneta (redaka) = 18828
- broj rijeci (stupaca) = 136471
- broj elemenata u sparse matrici = 2648308
- gustoca sparce matrice tf * idf = 0,00103068

Prilikom dodavanja elementa, u trenutnoj verziji, svaki algoritam provodi postupak predprocesiranja iz početka. To bi se trebalo optimizirati tako da se ažuriraju samo one vrijednosti koje su stvarno potrebne da se ažuriraju. TODO

Inicijalna implementacija vector space modela bila je iterativna. Dakle za svaki dokument pretprocesiranjem se odredio vektor TF * IDF, a prilikom rangiranja, za svaki dokument se izračunala mjera udaljenosti. Takva implementaija, za dani dataset dala je rezultat za red veličine 10s, što je neprihvatljivo. Trenutna implementacija algoritma koristi množenje sparse matrice i vektora (po svakom retku) i takva implementacija daje rezultat u vremenu od reda valičine 10ms, što je puno prihvatljivije.

Kao mjere udaljenosti razmatrane su euklidska i kosinusna udaljenost. Kosinusna udaljenost dala je vrijeme izvođenja upita ~25ms, dok je euklidska udaljenost dala vrijeme izvođenja upita ~40ms. Stoga je odabrana euklidska udaljenost.

3. Binomial independence.
Implementacija složenost algoritma ovisi o broju dokumenata nad kojima se vrši rangiranje. Konkretno, za dani upit potrebno je obići sve dokumente kako bi se dobila procijenjena vjerojatnosti $p(D_t|q, not r)$. Danu procjenu u teoriji je moguče predprocesirati, no budući da bi predprocesiranih podataka bilo broj_dokumenata * broj_tokena, to je u praksi nemoguče napraviti. Problem bi se moglo riješiti tako da se skup dokumenata podijeli na dovoljno male podskupine unutar kojih bi se onda radilo rangiranje.

Problem kod algoritma je što ako je ulaz jedan token, procijenjene težine za svaki dokument su iste i onda je nemoguče napraviti kvalitetno rangiranje. To bi se moglo riješiti tako da se na težinu za pojedini token doda normalizirani broj njegovog pojavljivanja unutar dokumenta.

TODO: analizirati formule i ostalo

-------------------------- 
Testno racunalo:
RAM: 7880944 kB; 1600MHz
CPU: Intel(R) Core(TM) i3-4010U CPU @ 1.70GHz
GPU: GeForce GT 720M; 96 Cuda Cores; 2048 MB
--------------------------
Docker:
Docker kontejneri pružaju nekoliko zanimljivih svojstava. U prvom redu kontejner pruža izoliranu okolinu za proces koji se u njemu izvršava. Nadalje olakšava se proces ažuriranja instanci aplikacije zato što se jednom krairana slika kontejnera može više puta instancirati kao konkretan kontejner. Na poslijetku, jedina ovisnost koja treba postojati na fizičkom stroju u kojem će se izvršavati proces koji je unutar docker kontejnera je sam docker i ništa više.
--------------------------
Digital ocean
Digital ocean se koristi kao (engl. deployment) okolina. Prednosti Digital oceana nad ostalim VPS pružateljima su:
* SSD diskovne jedinice
* optimizirana KVM virtualizacija
* povoljna cijena
* datacentri u Americi, Aziji i Europi
* jako dobra kontrolna ploča (engl. management panel)
--------------------------
Mongo
MongoDB je dokument baza podataka. Služi kako bi se u nju pohranili različiti ne nužno strukturirani objekti. MongoDB može raditi u više različitih načina rada, najvažniji su: replikacijski model (engl. replica set) i particionirani model (engl. sharded). U ovom radu korištena je samo jedna instance MongoDB baze, no u slučaju da je potrebno dobiti višu propusnost baze napravila bi se promjena konfiguracije u replikacijski model i pokrenulo bi se više instanci base. Promjena koja bi se morala napraviti s klijentske strane bila bi samo promjena konfiguracijskog niza znakova s kojim se klijent spaja na bazu.

Do padataka iz baze podataka pristupa se preko REST sučelja čija se implementacija nalazi u styria-task/database/rest.py.
REST sučelje:
GET  /api/documents               -> dohvača dokumente uz straničenje, HTTP parametri: pagenum, pagesize
POST /api/documents               -> kreira novi dokument ako već ne postoji
GET  /api/documents/count         -> dohvača ukupan broj dokumenata u sustavu
GET  /api/documents/{identifier}  -> dohvača pojedini dokument

Pokretanje REST sučelja baze podataka:
cd database
PYTHONPATH=~/path/to/styria-task PYTHONHASHSEED=0 ./run.sh

Varijablu okoline PYTHONHASHSEED je potrebno koristiti kako bi ugrađena hash funkcija vračala uvijek isti rezultat. Uz pomoć te funkcije se definira da li dokument već postoji u bazi podataka.
--------------------------
Redis

Distribution models:
* each client has whole dataset
* each client has a part of dataset
--------------------------
TIME:
* bag_of_words:
for each document -> list appent -> sort whole list -> ~0.19s
for each document -> heappush -> create whole list -> ~0.25
for each document -> heappush -> take first N -> ~0.19s
for each term -> dictionary[document_id] = bag_value -> 0.0s (selected model)

csr_matrix -> keep memory under control

* load nginx balancer i svojstvo reloadanja.
* cython i falcon, uwsgi

uWSGI:
uWSGI je aplikacijski server koji zna izvršavati WSGI python aplikaciju. uwsgi je žičani (engl. wire) protokol koji se koristi kako bi HTTP server kao što je Nginx znao komunicirati s uWSGI aplikacijom, dakle uwsgi je protokol aplikacijskog sloja. (https://en.wikipedia.org/wiki/Wire_protocol).
TODO: http://uwsgi-docs.readthedocs.org/en/latest/StatsServer.html

Nginx:
Nginx je visoko propusni (engl. high-performanse) HTTP server.

uWSGI + Nginx:
https://www.digitalocean.com/community/tutorials/how-to-set-up-uwsgi-and-nginx-to-serve-python-apps-on-ubuntu-14-04

BANCHMARK:
Za kvalitetan benchmark potrebno je imati odgovarajuci stroj koji moze opteretiti sustav koji se benchmarka, takodjer je potrebno imati kvalitetnu mrezu koja moze podnjeti veliku kolicinu prometa koja se generira prilikom izvodjenja banchmarka.
wrk alat: https://github.com/wg/wrk
wrk je HTTP benchmark alat napisan u programskom jeziku C. Karakterizira ga relativno mali izvorni kod i velika brzina rada.

primjer testa: wrk -c 100 -d 20 -t 4 http://localhost:8001/api/document -s query.lua
-c 100 -> 100 paralelnih konekcija
-d 20 -> 20s vrijeme trajanja testa
-t 4 -> 4 dretve za izvodjenje testa
-s query.lua -> konkretan request

TESTOVI (svaki test je ponavljan 5 put te je uzeta aritmeticka sredina)

* uWSGI vs gunicorn -> uWSGI odgovara na više upita po sekundi
--
WSGI naredba: uwsgi --http :8001 --wsgi-file computation.py --callable app --processes 4 --threads 1 --disable-logging --master
WRK naredba: wrk -c 100 -d 20 -t 4 http://localhost:8001/api/document -s query.lua
Normalizirani bag of words uWSGI s 4 procesa svaka s 1 dretvom u http nacinu rada -> 1767,23 req/s
--
Normalizirani bag of words gunicorn s 4 radnika -> 1245,64 req/s
WSGI naredba: gunicorn -w 4 computation:app -b localhost:8001 -t 120
WRK naredba: wrk -c 100 -d 20 -t 4 http://localhost:8001/api/document -s query.lua
--
Normalizirani bag of words nginx + uwsgi s 4 procesa u socket nacinu rada -> 1915,63 req/s
WRK naredba: wrk -c 100 -d 20 -t 4 http://infinity/api/document -s query.lua
--
Nginx je efikasniji od uwsgi servera u http nacinu rada. Iz čega slijedi da je optimalno koristiti uwsgi u socket nacinu rada iza Nginx servera.
--------------------------
Dependency management:
Cijeli projekt je trentno unutar jednog foldera. To bi se trebalo razložiti na više modula. TODO:  .
--------------------------
Osvrt na implementaciju sa stajališta programskog inženjera
Svaki algoritam je tipa IRAlgorithm koji posjeduje tri metode. config putem koje se prima nekakva konfiguracija algoritma, ako takva za dani algoritam postoji. process kroz koju se radi predprocesiranje podataka. run koja vrača konkretne rezultate. Kako bi se izbjeglo pokretanje predprocesiranja svaki put kada se treba pokrenuti algoritam uveden je razred AlgorithmBox koji posjeduje instance svih dostupnih algoritama u varijabli available_algorithms. U varijabli prepared_algorithms nalaze se samo one instance algoritama za koje je već proveden proces predprocesiranja. Varijabla prepared_algorithms se prilikom svakog postavljanja dokumenata kroz setter files postavi na prazni dictionary. Na taj način se postiže da se kod idučeg dohvačanja nekog algoritma ponovno forsira proces predprocesiranja. Mana ovog pristupa je što svaki algoritam za sebe drži kopiju svih dokumenata i ponavljanje predprocesiranja za svaki algoritam posebno. Prednost je, po mojem mišljenju, svojstvo da svaki algoritam ima izolirani skup podataka s kojim može činiti što je već potrebno kako bi algoritam valjano radio. Odlučio sam se za taj pristup zato što je memorija manji problem od nekakve jednostavnosti korištenja i važnosti da je svaki algoritam za sebe izoliran. 
--------------------------
Deployment okolina:
Svi upiti klijenata dolaze na Nginx load balancer koji ima izrazito veliku propusnost. Nakon toga load banancer prosljedjuje upit na worker instance koje svaka za sebe imaju cijeli dataset i znaju vratiti odgovarajuci rezultat. Dataset worker instance preuzimaju od db interface instance, a ne direktno iz baze. Trenutno je u deploymentu samo jedna instanca sucelja prema bazi, ali u produkciji tu moze biti opet load balancer i vise instanci interface-a prema bazi podataka. Baza podataka je MongoDB, takodjer samo jedna instanca, no u praksi tu moze doci mongo replica set ili mongo shard cluster.

Kao sto se vidi na grafu, sve instance imaju simbolicka imena (FQDN). To je takodjer izrazito bitno jer se time postize transparentnost pristupa i migracijska transparentnost. U konkretnoj implementaciji sva imena su definirana u /etc/hosts file-u na deploy stroju, no u produkciji ce imene biti definirana na redundantnim DNS serverima.
--------------------------
Upute za pokretanje:
cd infinity
potrebno je postaviti python virtualni environment ili instalirati ovisnosti koje su navedene u requirements.txt TODO: napisati skriptu koja se pokrece sa source setup.py
python console.py -> CLI sucelje (argumenti su: -q "query" -a "bag_of_words|vector_space|binary_indenpendence" -n number_of_results)
--------------------------
Ovisnosti:
falcon -> web server
uwsgi -> wsgi kontejner
gunicorn -> samo korišten u testiranju
numpy -> matrične operacije
pymongo -> adapter za MongoDB
redis -> pub/sub, raspodijeljeni lock
scikit-learn -> matrične operacije nad sparse matricama
scipy -> sparse matrice
nginx -> http server, load balancer
docker -> kontejner za procese
angular -> MVC web framework
materializecss -> google material design css
--------------------------
Budući da u opčenitom slučaju postoji potreba da dokumenti budu tajni, komunikacija između klijenta i poslužitalja odvija se putem protokola HTTPS. (TODO, priority low)
--------------------------
PS
infinity > gugol

