2. Vector space algorithm

Veličina problema:
- broj dokumeneta (redaka) = 18828
- broj rijeci (stupaca) = 136471
- broj elemenata u sparse matrici = 2648308
- gustoca sparce matrice tf * idf = 0,00103068

-------------------------- 
Testno racunalo:
RAM: 7880944 kB; 1600MHz
CPU: Intel(R) Core(TM) i3-4010U CPU @ 1.70GHz
GPU: GeForce GT 720M; 96 Cuda Cores; 2048 MB
--------------------------
Docker:
Docker kontejneri pružaju nekoliko zanimljivih svojstava. U prvom redu kontejner pruža izoliranu okolinu za proces koji se u njemu izvršava. Nadalje olakšava se proces ažuriranja instanci aplikacije zato što se jednom krairana slika kontejnera može više puta instancirati kao konkretan kontejner. Na poslijetku, jedina ovisnost koja treba postojati na fizičkom stroju u kojem će se izvršavati proces koji je unutar docker kontejnera je sam docker i ništa više.
--------------------------
Digital ocean
Digital ocean se koristi kao (engl. deployment) okolina. Prednosti Digital oceana nad ostalim VPS pružateljima su:
* SSD diskovne jedinice
* optimizirana KVM virtualizacija
* povoljna cijena
* datacentri u Americi, Aziji i Europi
* jako dobra kontrolna ploča (engl. management panel)
--------------------------
Mongo
MongoDB je dokument baza podataka. Služi kako bi se u nju pohranili različiti ne nužno strukturirani objekti. MongoDB može raditi u više različitih načina rada, najvažniji su: replikacijski model (engl. replica set) i particionirani model (engl. sharded). U ovom radu korištena je samo jedna instance MongoDB baze, no u slučaju da je potrebno dobiti višu propusnost baze napravila bi se promjena konfiguracije u replikacijski model i pokrenulo bi se više instanci base. Promjena koja bi se morala napraviti s klijentske strane bila bi samo promjena konfiguracijskog niza znakova s kojim se klijent spaja na bazu.

Do padataka iz baze podataka pristupa se preko REST sučelja čija se implementacija nalazi u styria-task/database/rest.py.
REST sučelje:
GET  /api/documents               -> dohvača dokumente uz straničenje, HTTP parametri: pagenum, pagesize
POST /api/documents               -> kreira novi dokument ako već ne postoji
GET  /api/documents/count         -> dohvača ukupan broj dokumenata u sustavu
GET  /api/documents/{identifier}  -> dohvača pojedini dokument

Pokretanje REST sučelja baze podataka:
cd database
PYTHONPATH=~/path/to/styria-task PYTHONHASHSEED=0 ./run.sh

Varijablu okoline PYTHONHASHSEED je potrebno koristiti kako bi ugrađena hash funkcija vračala uvijek isti rezultat. Uz pomoć te funkcije se definira da li dokument već postoji u bazi podataka.
--------------------------
Redis

Distribution models:
* each client has whole dataset
* each client has a part of dataset
--------------------------
TIME:
* bag_of_words:
for each document -> list appent -> sort whole list -> ~0.19s
for each document -> heappush -> create whole list -> ~0.25
for each document -> heappush -> take first N -> ~0.19s
for each term -> dictionary[document_id] = bag_value -> 0.0s (selected model)

csr_matrix -> keep memory under control

* load nginx balancer i svojstvo reloadanja.
* cython i falcon, uwsgi

uWSGI:
uWSGI je aplikacijski server koji zna izvršavati WSGI python aplikaciju. uwsgi je žičani (engl. wire) protokol koji se koristi kako bi HTTP server kao što je Nginx znao komunicirati s uWSGI aplikacijom, dakle uwsgi je protokol aplikacijskog sloja. (https://en.wikipedia.org/wiki/Wire_protocol).
TODO: http://uwsgi-docs.readthedocs.org/en/latest/StatsServer.html

Nginx:
Nginx je visoko propusni (engl. high-performanse) HTTP server.

uWSGI + Nginx:
https://www.digitalocean.com/community/tutorials/how-to-set-up-uwsgi-and-nginx-to-serve-python-apps-on-ubuntu-14-04

BANCHMARK:
Za kvalitetan benchmark potrebno je imati odgovarajuci stroj koji moze opteretiti sustav koji se benchmarka, takodjer je potrebno imati kvalitetnu mrezu koja moze podnjeti veliku kolicinu prometa koja se generira prilikom izvodjenja banchmarka.
wrk alat: https://github.com/wg/wrk
wrk je HTTP benchmark alat napisan u programskom jeziku C. Karakterizira ga relativno mali izvorni kod i velika brzina rada.

primjer testa: wrk -c 100 -d 20 -t 4 http://localhost:8001/api/document -s query.lua
-c 100 -> 100 paralelnih konekcija
-d 20 -> 20s vrijeme trajanja testa
-t 4 -> 4 dretve za izvodjenje testa
-s query.lua -> konkretan request

TESTOVI (svaki test je ponavljan 5 put te je uzeta aritmeticka sredina)

* uWSGI vs gunicorn -> uWSGI odgovara na više upita po sekundi
--
WSGI naredba: uwsgi --http :8001 --wsgi-file computation.py --callable app --processes 4 --threads 1 --disable-logging --master
WRK naredba: wrk -c 100 -d 20 -t 4 http://localhost:8001/api/document -s query.lua
Normalizirani bag of words uWSGI s 4 procesa svaka s 1 dretvom u http nacinu rada -> 1767,23 req/s
--
Normalizirani bag of words gunicorn s 4 radnika -> 1245,64 req/s
WSGI naredba: gunicorn -w 4 computation:app -b localhost:8001 -t 120
WRK naredba: wrk -c 100 -d 20 -t 4 http://localhost:8001/api/document -s query.lua
--
Normalizirani bag of words nginx + uwsgi s 4 procesa u socket nacinu rada -> 1915,63 req/s
WRK naredba: wrk -c 100 -d 20 -t 4 http://infinity/api/document -s query.lua
--
Nginx je efikasniji od uwsgi servera u http nacinu rada. Iz čega slijedi da je optimalno koristiti uwsgi u socket nacinu rada iza Nginx servera.
--------------------------
Dependency management:
Cijeli projekt je trentno unutar jednog foldera. To bi se trebalo razložiti na više modula. TODO:  .
--------------------------
Osvrt na implementaciju sa stajališta programskog inženjera
 
--------------------------
Deployment okolina:
Svi upiti klijenata dolaze na Nginx load balancer koji ima izrazito veliku propusnost. Nakon toga load banancer prosljedjuje upit na worker instance koje svaka za sebe imaju cijeli dataset i znaju vratiti odgovarajuci rezultat. Dataset worker instance preuzimaju od db interface instance, a ne direktno iz baze. Trenutno je u deploymentu samo jedna instanca sucelja prema bazi, ali u produkciji tu moze biti opet load balancer i vise instanci interface-a prema bazi podataka. Baza podataka je MongoDB, takodjer samo jedna instanca, no u praksi tu moze doci mongo replica set ili mongo shard cluster.

Kao sto se vidi na grafu, sve instance imaju simbolicka imena (FQDN). To je takodjer izrazito bitno jer se time postize transparentnost pristupa i migracijska transparentnost. U konkretnoj implementaciji sva imena su definirana u /etc/hosts file-u na deploy stroju, no u produkciji ce imene biti definirana na redundantnim DNS serverima.
--------------------------
Upute za pokretanje:
cd infinity
potrebno je postaviti python virtualni environment ili instalirati ovisnosti koje su navedene u requirements.txt TODO: napisati skriptu koja se pokrece sa source setup.py
python console.py -> CLI sucelje (argumenti su: -q "query" -a "bag_of_words|vector_space|binary_indenpendence" -n number_of_results)
--------------------------
Ovisnosti:
falcon -> web server
uwsgi -> wsgi kontejner
gunicorn -> samo korišten u testiranju
numpy -> matrične operacije
pymongo -> adapter za MongoDB
redis -> pub/sub, raspodijeljeni lock
scikit-learn -> matrične operacije nad sparse matricama
scipy -> sparse matrice
nginx -> http server, load balancer
docker -> kontejner za procese
angular -> MVC web framework
materializecss -> google material design css
--------------------------
Budući da u opčenitom slučaju postoji potreba da dokumenti budu tajni, komunikacija između klijenta i poslužitalja odvija se putem protokola HTTPS. (TODO, priority low)
--------------------------
PS
infinity > gugol

